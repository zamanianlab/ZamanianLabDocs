
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="An internal resource explaining and documenting lab pipelines">
      
      
      
        <link rel="canonical" href="https://zamanianlab.org/ZamanianLabDocs/pipelines_server/">
      
      
        <meta name="author" content="Zamanian Lab">
      
      <link rel="shortcut icon" href="../images/dna.svg">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-6.1.7">
    
    
      
        <title>Server Pipelines - Zamanian Lab Docs</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.19753c6b.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.196e0c26.min.css">
        
          
          
          <meta name="theme-color" content="#000000">
        
      
    
    
    
      
        
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Lato",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
      <link rel="stylesheet" href="../stylesheets/extra_colors.css">
    
    
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="red">
      
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#server-pipelines" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="https://zamanianlab.org/ZamanianLabDocs" title="Zamanian Lab Docs" class="md-header-nav__button md-logo" aria-label="Zamanian Lab Docs">
      
  <img src="../images/dna.svg" alt="logo">

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            Zamanian Lab Docs
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              Server Pipelines
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/zamanianlab/ZamanianLabDocs/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    zamanianlab/ZamanianLabDocs
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://zamanianlab.org/ZamanianLabDocs" title="Zamanian Lab Docs" class="md-nav__button md-logo" aria-label="Zamanian Lab Docs">
      
  <img src="../images/dna.svg" alt="logo">

    </a>
    Zamanian Lab Docs
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/zamanianlab/ZamanianLabDocs/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    zamanianlab/ZamanianLabDocs
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../labmanual/" class="md-nav__link">
      Lab Manual
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../protocols/protocols/" class="md-nav__link">
      Lab Protocols
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../labsheets/" class="md-nav__link">
      Lab Sheets
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5" >
    <label class="md-nav__link" for="nav-5">
      Computational Guide
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Computational Guide" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        <span class="md-nav__icon md-icon"></span>
        Computational Guide
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../comp_overview/" class="md-nav__link">
      Overview
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../comp_local/" class="md-nav__link">
      Local Environment
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../comp_github/" class="md-nav__link">
      GitHub
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../comp_conda/" class="md-nav__link">
      Conda
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../comp_homebrew/" class="md-nav__link">
      Homebrew
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6" checked>
    <label class="md-nav__link" for="nav-6">
      Pipelines
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Pipelines" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        <span class="md-nav__icon md-icon"></span>
        Pipelines
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../pipelines_overview/" class="md-nav__link">
      Overview
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../pipelines_storage/" class="md-nav__link">
      Data Storage
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../pipelines_local/" class="md-nav__link">
      Local Pipelines
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Server Pipelines
        <span class="md-nav__icon md-icon"></span>
      </label>
    
    <a href="./" class="md-nav__link md-nav__link--active">
      Server Pipelines
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#a-center-for-high-throughput-computing-chtc" class="md-nav__link">
    A. Center for High-throughput Computing (CHTC)
  </a>
  
    <nav class="md-nav" aria-label="A. Center for High-throughput Computing (CHTC)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-htc-system" class="md-nav__link">
    The HTC System
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deploying-pipelines" class="md-nav__link">
    Deploying Pipelines
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#b-docker" class="md-nav__link">
    B. Docker
  </a>
  
    <nav class="md-nav" aria-label="B. Docker">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#building-docker-images" class="md-nav__link">
    Building Docker Images
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#testing-docker-pipelines" class="md-nav__link">
    Testing Docker Pipelines
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../pipelines_wrmxpress/" class="md-nav__link">
      wrmXpress Pipelines
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../resources/" class="md-nav__link">
      Resources
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#a-center-for-high-throughput-computing-chtc" class="md-nav__link">
    A. Center for High-throughput Computing (CHTC)
  </a>
  
    <nav class="md-nav" aria-label="A. Center for High-throughput Computing (CHTC)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-htc-system" class="md-nav__link">
    The HTC System
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deploying-pipelines" class="md-nav__link">
    Deploying Pipelines
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#b-docker" class="md-nav__link">
    B. Docker
  </a>
  
    <nav class="md-nav" aria-label="B. Docker">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#building-docker-images" class="md-nav__link">
    Building Docker Images
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#testing-docker-pipelines" class="md-nav__link">
    Testing Docker Pipelines
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/zamanianlab/ZamanianLabDocs/edit/master/docs/pipelines_server.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                <h1 id="server-pipelines">Server Pipelines</h1>
<p>Our lab has access to powerful computing resources and support through the <a href="https://chtc.cs.wisc.edu/">Center for High-Throughput Computing (CHTC)</a>. Our core bioinformatics and image processing pipelines will be deployed through CHTC servers. All pipelines will be maintained on <a href="https://www.github.com">GitHub</a> and associated with <a href="https://www.docker.com">Docker</a> environments to ensure reproducibility. Many of our pipelines will use <a href="https://www.nextflow.io/">Nextflow</a>.</p>
<p>In general, pipelines will be run in three steps:</p>
<ul>
<li><strong>Staging:</strong> input files will be transferred to the CHTC server from lab storage</li>
<li><strong>Pipeline:</strong> files will be processed using established pipelines</li>
<li><strong>Output:</strong> desired outputs will be transferred from the CHTC server to lab storage</li>
</ul>
<h2 id="a-center-for-high-throughput-computing-chtc">A. Center for High-throughput Computing (CHTC)</h2>
<p>Consult official <a href="https://chtc.cs.wisc.edu/">CHTC</a> and <a href="https://research.cs.wisc.edu/htcondor/">HTCondor</a> documentation before getting started. Register for an account using this <a href="https://chtc.cs.wisc.edu/uw-research-computing/form">form</a>.</p>
<p><img src="../images/chtc_flowchart.png" width="100%"></p>
<h3 id="the-htc-system">The HTC System</h3>
<ol>
<li>
<p>Execute (Compute) nodes</p>
<p>The CHTC has an extensive set of execute nodes. To establish priority access for certain pipelines, our lab has secured a prioritized node that can be accessed on-demand using a designated flag.</p>
<ul>
<li>Typical nodes: 20 cores, 128 GB RAM</li>
<li><a href="https://chtc.cs.wisc.edu/uw-research-computing/high-memory-jobs">High-memory nodes</a>: e.g., 80 cores, 4 TB RAM</li>
<li>Dedicated lab node: 40 cores (80 hyperthreading), 512 GB RAM, 3.8 TB HD  </li>
</ul>
</li>
<li>
<p>Submit nodes</p>
<p>Jobs on the CHTC are deployed from submit nodes. You can <code>ssh</code> into our assigned submit node (submit2) to run and monitor jobs using your UW net-id and password.</p>
<p><code>ssh {net-id}@submit2.chtc.wisc.edu</code></p>
<p><strong>Note:</strong> If you correctly updated your <code>~/.bash_profile</code> by following the <a href="../comp_local/">macOS environment setup instructions</a>, then you can use the simple <code>submit</code> to <code>ssh</code> into the node.</p>
</li>
<li>
<p>File system</p>
<p>Each net-id is associated with a <code>home</code> folder, where we manage job submission scripts. Our lab also has a shared <code>staging</code> folder, for transfer of large files in and out of the CHTC system. The CHTC does not use a shared file system, but you can request the storage you need for any given job.</p>
<div class="highlight"><pre><span></span><code>/
├── home/{net-id}/                    [quota: 20 GB, submit script dir]
└── staging/groups/zamanian_group/    [quota: 1 TB | 100 files]
    └── input/                        [input dir: unprocessed (raw) data]
    └── output/                       [output dir: processed job outputs]
    └── WBP.tar.gz                    [permanent storage of WBP data]
</code></pre></div>
</li>
</ol>
<h3 id="deploying-pipelines">Deploying Pipelines</h3>
<ol>
<li>
<p><strong>Staging -</strong> transfer input data for processing (ResearchDrive -&gt; CHTC)</p>
<p>1A. <strong>Globus transfer</strong></p>
<p>In almost all cases, you will use <a href="https://it.wisc.edu/it-projects/globus-research-data-management-project/">Globus</a> to transfer your input data from ResearchDrive to the CHTC staging input folder. Globus is the fastest and most secure transfer method, and allows for transfer from any file system that has a Globus endpoint installed. Most raw data on ResearchDrive is unarchived and uncompressed. However, our pipelines expect a single archived folder (.tar) as input and will deliver a single archived folder as output. Use the workflow below to transfer an unarchived folder on ResearchDrive to CHTC input and archive it after arrival. See the <a href="https://kb.wisc.edu/researchdata/internal/page.php?id=108855">KB</a> for further instructions and necessary preparations for initiating your first transfer.</p>
<details class="example"><summary>Globus transfer</summary><ol>
<li>Login to the <a href="https://app.globus.org/">Globus web interface</a> with your NetID</li>
<li>If transferring from a personal computer, install and start <a href="https://www.globus.org/globus-connect- personal">Globus Connect Personal</a>.</li>
<li>If transferring from ResearchDrive, first create a kerberos ticket by running the command <code>ssh [netid]@doit-rci- 00025.doit.wisc.edu</code>.</li>
<li>In the web interface, set the view to two panels using the icon on the top right.</li>
<li>On one side of the interface, click Collection and choose the desired endpoint (<code>chtc#staging</code>, <code>wisc-drive</code>, or your personal   computer).</li>
<li>Choose the other endpoint for the other side of the interface.</li>
<li>Type <code>/staging/groups/zamanian_group/</code> into the Path box of the <code>chtc#staging</code> collection and press Enter (you may be required to  login with your NetID   again). Use <code>/mnt/researchdrive/mzamanian/</code> for <code>wisc-drive</code>.</li>
<li>Navigate to the desired directories.</li>
<li>Drag and drop files to transfer them; you will receive an email upon transfer completion.</li>
<li>Exit the SSH once finished transferring to/from ResearchDrive.</li>
<li>Login to the transfer server and archive the directories in <code>input/</code> and <code>metadata/</code> with the command <code>tar -cvf {plate}.tar   {plate}</code>.</li>
<li>Delete the original, unarchived directories.</li>
</ol>
</details>
<p>1B. <strong>Command line transfer with smbclient</strong></p>
<p>It is also possible to transfer via smbclient using the terminal. The following code will also archive the data upon arrival.</p>
<details><summary>ResearchDrive -&gt; CHTC transfer of unarchived raw data folder (archived on arrival)</summary><div class="highlight"><pre><span></span><code><span class="c1"># Log into transfer server and navigate to staging input dir</span>
ssh <span class="o">{</span>net-id<span class="o">}</span>@transfer.chtc.wisc.edu
<span class="nb">cd</span> /staging/groups/zamanian_group/input/

<span class="c1"># Example of transferring sequencing data</span>
smbclient -k //research.drive.wisc.edu/mzamanian/ -D <span class="s2">&quot;UWBC-Dropbox/Bioinformatics Resource Center&quot;</span> -Tc 201105_AHLVWJDSXY.tar <span class="s2">&quot;201105_AHLVWJDSXY&quot;</span>

<span class="c1"># Example of transferring ImageXpress data</span>
smbclient -k //research.drive.wisc.edu/mzamanian/ -D <span class="s2">&quot;ImageXpress/raw&quot;</span> -Tc <span class="m">20201118</span>-p01-MZ_172.tar <span class="s2">&quot;20201118-p01-MZ_172.tar&quot;</span>
</code></pre></div>
</details>
<details><summary>ResearchDrive -&gt; CHTC transfer of unarchived metadata folder (archived on arrival)</summary><div class="highlight"><pre><span></span><code><span class="c1"># Log into transfer server and navigate to staging metadata dir</span>
ssh <span class="o">{</span>net-id<span class="o">}</span>@transfer.chtc.wisc.edu
<span class="nb">cd</span> /staging/groups/zamanian_group/metadata/

<span class="c1"># Example of transferring ImageXpress metadata</span>
smbclient -k //research.drive.wisc.edu/mzamanian/ -D <span class="s2">&quot;ImageXpress/metadata&quot;</span> -Tc <span class="m">20201118</span>-p01-MZ_172.tar <span class="s2">&quot;20201118-p01-MZ_172&quot;</span>
</code></pre></div>
</details>
<p><strong>Note:</strong> If you correctly updated your <code>~/.bash_profile</code> by following the <a href="../comp_local/">macOS environment setup instructions</a>, then you can use the simple <code>transfer</code> to <code>ssh</code> into the node.</p>
<p>For ImageXpress data, an entire experiment may include &gt;10 plates that will take hours to days to transfer. To facilitate batch transfers, we have included two scripts in the <code>input/</code> and <code>metadata/</code> directories of <code>/staging/groups/zamanian_group/</code> to help with batch transfer.</p>
<details><summary>Batch transfer via custom scripts and <code>screen</code></summary><div class="tabbed-set" data-tabs="1:2"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><label for="__tabbed_1_1">Instructions</label><div class="tabbed-content">
<ol>
<li>Use a terminal text editor (e.g., <code>vim</code> or <code>nano</code>) to edit the plate list in <code>/staging/groups/zamanian_group/input/plates.txt</code> such that there is a    single plate name per line. Also include a blank line at the end of the file.</li>
<li>Use the commands <code>sh transfer_images.sh</code> (from the <code>input/</code> directory) and <code>sh transfer_metadata.sh</code> (from the <code>metadata/</code> directory) to transfer the images and metadata, respectively.</li>
<li>Use the <code>screen</code> tool to maintain a continuous process in the background, allowing you to close your SSH session.</li>
</ol>
</div>
<input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><label for="__tabbed_1_2">Sample screen commands</label><div class="tabbed-content">
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="c1"># Log into transfer server and navigate to staging input dir</span>
ssh <span class="o">{</span>net-id<span class="o">}</span>@transfer.chtc.wisc.edu
<span class="nb">cd</span> /staging/groups/zamanian_group/input/

<span class="c1"># Start a screen named &#39;transfer&#39;</span>
screen -S transfer

<span class="c1"># Initiate the transfer</span>
sh transfer_images.sh

<span class="c1"># Detach from the screen by pressing Ctrl+a and then d</span>
<span class="c1"># Reattach to the screen</span>
screen -r transfer

<span class="c1"># Close the screen</span>
<span class="nb">exit</span>
</code></pre></div>
</td></tr></table>
</div>
</div>
</details>
<p>1C. <strong>Drag-and-drop transfer</strong></p>
<p>Transferring input data should be performed with Globus (1A) or background smblient processes (1B). However, smaller files such as metadata or auxiliary parameter files can be moved to the staging directory or one's home directory on the submit2 server with drag-and-drop SFTP clients such as Transmit, CyberDuck, or FileZilla.</p>
<p>1D. <strong>Command line transfer with <code>scp</code></strong></p>
<p>A final option for transfer of small files is via the <code>scp</code> command:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># transfer to staging</span>
scp <span class="o">[</span><span class="nb">local</span> file<span class="o">]</span> <span class="o">{</span>net-id<span class="o">}</span>@transfer.chtc.wisc.edu:/staging/groups/zamanian_group/input/

<span class="c1"># transfer to home</span>
scp <span class="o">[</span><span class="nb">local</span> file<span class="o">]</span> <span class="o">{</span>net-id<span class="o">}</span>@submit2.chtc.wisc.edu:/home/<span class="o">{</span>net-id<span class="o">}</span>
</code></pre></div>
<details class="danger" open="open"><summary>Warning!</summary><p>Do not use options 1C or 1D for the transfer of many files or large files &gt;100 MB, as these methods are unstable and can be unpredictable. For batch transfer or transfer of large files, the recommended method is Globus (1A).</p>
</details>
</li>
<li>
<p><strong>Pipeline -</strong> Submit and manage CHTC jobs</p>
<p>CHTC uses HTCondor for job scheduling. Submission files should follow lab conventions and be consistent with the CHTC documentation. Two example submit scripts with annotations are shown below. This submit scripts (Core_RNAseq-nf.sub/wrmXpress.sub) load a pre-defined Docker environment and run a bash executable script (Core_RNAseq-nf.sh/wrmXpress.sh) with defined arguments on the execute node. Other options define log files, resource requirements, and transfer of files in/out of <code>home</code>. Large files should not be transferred in/out of <code>home</code>, but you may need to transfer auxiliary files (for example, the parameters YAML file for wrmXpress jobs). We transfer in our large data through <code>/staging/groups/zamanian_group/input/</code> and we move job output files to <code>/staging/groups/zamanian_group/output/</code> within the job executable script to avoid their transfer to <code>home</code> upon job completion. The only files that should be transferred back to <code>home</code> are small log files.</p>
<details><summary>Example CHTC job submission scripts (.sub / .sh)</summary><div class="tabbed-set" data-tabs="2:4"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><label for="__tabbed_2_1">Core_RNAseq-nf.sub</label><div class="tabbed-content">
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code># Core_RNAseq-nf.sub
# Input data in /staging/{net-id}/input/$(dir)
# Run: condor_submit Core_RNAseq-nf.sub dir=191211_AHMMC5DMXX script=Core_RNAseq-nf.sh

# request Zamanian Lab server
Accounting_Group = PathobiologicalSciences_Zamanian

# load docker image; request execute server with staging
universe = docker
docker_image = zamanianlab/chtc-rnaseq:v1
Requirements = (Target.HasCHTCStaging == true)

# executable (/home/{net-id}/) and arguments
executable = $(script)
arguments = $(dir)

# log, error, and output files
log = $(dir)_$(Cluster)_$(Process).log
error = $(dir)_$(Cluster)_$(Process).err
output = $(dir)_$(Cluster)_$(Process).out

# transfer files in-out of /home/{net-id}/
transfer_input_files =
should_transfer_files = YES
when_to_transfer_output = ON_EXIT

# memory, disk and CPU requests
request_cpus = 80
request_memory = 500GB
request_disk = 1500GB

# submit 1 job
queue 1
### END
</code></pre></div>
</td></tr></table>
</div>
<input id="__tabbed_2_2" name="__tabbed_2" type="radio" /><label for="__tabbed_2_2">Core_RNAseq-nf.sh</label><div class="tabbed-content">
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash</span>

<span class="c1"># set home () and mk dirs</span>
<span class="nb">export</span> <span class="nv">HOME</span><span class="o">=</span><span class="nv">$PWD</span>
mkdir input work output

<span class="c1"># echo core, thread, and memory</span>
<span class="nb">echo</span> <span class="s2">&quot;CPU threads: </span><span class="k">$(</span>grep -c processor /proc/cpuinfo<span class="k">)</span><span class="s2">&quot;</span>
grep <span class="s1">&#39;cpu cores&#39;</span> /proc/cpuinfo <span class="p">|</span> uniq
<span class="nb">echo</span> <span class="k">$(</span>free -g<span class="k">)</span>

<span class="c1"># transfer input data from staging ($1 is ${dir} from args)</span>
cp -r /staging/groups/zamanian_group/input/<span class="nv">$1</span>.tar input
<span class="nb">cd</span> input <span class="o">&amp;&amp;</span> tar -xvf <span class="nv">$1</span>.tar <span class="o">&amp;&amp;</span> rm <span class="nv">$1</span>.tar <span class="o">&amp;&amp;</span> mv */*/* <span class="nv">$1</span> <span class="o">&amp;&amp;</span> <span class="nb">cd</span> ..

<span class="c1"># clone nextflow git repo</span>
git clone https://github.com/zamanianlab/Core_RNAseq-nf.git

<span class="c1"># run nextflow command</span>
<span class="nb">export</span> <span class="nv">NXF_OPTS</span><span class="o">=</span><span class="s1">&#39;-Xms1g -Xmx8g&#39;</span>
nextflow run Core_RNAseq-nf/WB-pe.nf -w work -c Core_RNAseq-nf/chtc.config --dir <span class="nv">$1</span><span class="se">\</span>
   --star --qc --release <span class="s2">&quot;WBPS15&quot;</span> --species <span class="s2">&quot;brugia_malayi&quot;</span> --prjn <span class="s2">&quot;PRJNA10729&quot;</span> --rlen <span class="s2">&quot;150&quot;</span>

<span class="c1"># rm files you don&#39;t want transferred back to /home/{net-id}</span>
rm -r work input

<span class="c1"># tar output folder and delete it</span>
<span class="nb">cd</span> output <span class="o">&amp;&amp;</span> tar -cvf <span class="nv">$1</span>.tar <span class="nv">$1</span> <span class="o">&amp;&amp;</span> rm -r <span class="nv">$1</span> <span class="o">&amp;&amp;</span> <span class="nb">cd</span> ..

<span class="c1"># remove staging output tar if there from previous run</span>
rm -f /staging/groups/zamanian_group/output/<span class="nv">$1</span>.tar

<span class="c1"># mv large output files to staging output folder; avoid their transfer back to /home/{net-id}</span>
mv output/<span class="nv">$1</span>.tar /staging/groups/zamanian_group/output/
</code></pre></div>
</td></tr></table>
</div>
<input id="__tabbed_2_3" name="__tabbed_2" type="radio" /><label for="__tabbed_2_3">wrmXpress.sub</label><div class="tabbed-content">
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code># Input data: /staging/groups/zamanian_group/input/${plate}.tar
# Parameters: $HOME/${plate}.yml
# Run: condor_submit wrmXpress.sub script=wrmXpress.sh plate=20211105-p01-EJG_948

# request Zamanian Lab server
Accounting_Group = PathobiologicalSciences_Zamanian

# load docker image; request execute server with large data staging
universe = docker
docker_image = zamanianlab/chtc-wrmxpress:v1
Requirements = (Target.HasCHTCStaging == true)

# executable (/home/{net-id}/) and arguments
executable = $(script)
arguments = $(plate)

# log, error, and output files
log = $(plate)_$(Cluster)_$(Process).log
error = $(plate)_$(Cluster)_$(Process).err
output = $(plate)_$(Cluster)_$(Process).out

# transfer files in-out of /home/{net-id}/
transfer_input_files = $(plate).yml
should_transfer_files = YES
when_to_transfer_output = ON_EXIT

# memory, disk and CPU requests
request_cpus = 1
request_memory = 8GB
request_disk = 10GB

# submit a job for each directory in plate_list.txt
queue plate from plate_list.txt
### END
</code></pre></div>
</td></tr></table>
</div>
<input id="__tabbed_2_4" name="__tabbed_2" type="radio" /><label for="__tabbed_2_4">wrmXpress.sh</label><div class="tabbed-content">
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash</span>

<span class="c1"># set home () and mk dirs</span>
<span class="nb">export</span> <span class="nv">HOME</span><span class="o">=</span><span class="nv">$PWD</span>
mkdir input
mkdir metadata
mkdir output/
mkdir work/

git clone https://github.com/zamanianlab/wrmXpress.git

<span class="c1"># echo core, thread, and memory</span>
<span class="nb">echo</span> <span class="s2">&quot;CPU threads: </span><span class="k">$(</span>grep -c processor /proc/cpuinfo<span class="k">)</span><span class="s2">&quot;</span>
grep <span class="s1">&#39;cpu cores&#39;</span> /proc/cpuinfo <span class="p">|</span> uniq
<span class="nb">echo</span> <span class="k">$(</span>free -g<span class="k">)</span>

<span class="c1"># transfer and decompress input data from staging ($1 is ${dir} from args)</span>
tar -xf /staging/groups/zamanian_group/input/<span class="nv">$1</span>.tar -C input/

<span class="c1"># deprecated</span>
<span class="c1"># cp -r /staging/groups/zamanian_group/input/$1.tar input</span>
<span class="c1"># cd $input &amp;&amp; tar --strip-components 5 -xvf $1.tar &amp;&amp; cd $HOME</span>

<span class="c1"># transfer and decompress metadata from staging ($1 is ${dir} from args)</span>
tar -xf /staging/groups/zamanian_group/metadata/<span class="nv">$1</span>.tar -C metadata

<span class="c1"># deprecated</span>
<span class="c1"># cd metadata &amp;&amp; tar -xvf $1.tar &amp;&amp; rm $1.tar &amp;&amp; mv */*/* $1 &amp;&amp; cd $HOME</span>

<span class="c1"># run the wrapper</span>
python Core_imgproc/wrapper.py <span class="nv">$1</span>.yml <span class="nv">$1</span>

<span class="c1"># tar output folder and delete it</span>
mv output <span class="nv">$1</span>
mv <span class="nv">$1</span>.yml <span class="nv">$1</span>
tar -cvf <span class="nv">$1</span>.tar <span class="nv">$1</span> <span class="o">&amp;&amp;</span> rm -r <span class="nv">$1</span>

<span class="c1"># remove staging output tar if there from previous run</span>
rm -f /staging/groups/zamanian_group/output/<span class="nv">$1</span>.tar

<span class="c1"># mv large output files to staging output folder; avoid their transfer back to /home/{net-id}</span>
mv <span class="nv">$1</span>.tar /staging/groups/zamanian_group/output/
</code></pre></div>
</td></tr></table>
</div>
</div>
</details>
<p>Log into submit node to submit a job,</p>
<div class="highlight"><pre><span></span><code>ssh <span class="o">{</span>net-id<span class="o">}</span>@submit2.chtc.wisc.edu

condor_submit Core_RNAseq-nf.sub <span class="nv">dir</span><span class="o">=</span>191211_AHMMC5DMXX <span class="nv">script</span><span class="o">=</span>Core_RNAseq-nf.sh
</code></pre></div>
<details><summary>Other useful commands for monitoring and managing jobs</summary><div class="highlight"><pre><span></span><code><span class="c1"># check on job status</span>
  condor_q

<span class="c1"># remove a specific job</span>
  condor_rm <span class="o">[</span>job id<span class="o">]</span>

<span class="c1"># remove all jobs for user</span>
  condor_rm <span class="nv">$USER</span>

<span class="c1"># interative shell to running job on remote machine</span>
  condor_ssh_to_job <span class="o">[</span>job id<span class="o">]</span>
  <span class="nb">exit</span>
</code></pre></div>
</details>
</li>
<li>
<p><strong>Output -</strong> transfer output data (CHTC -&gt; ResearchDrive)</p>
<p>To transfer your job output folder from the CHTC staging output directory to Research Drive, it is easist to use an SFTP client (e.g., CyberDuck, Transmit, FileZilla) to transfer the tar files to your local computer, and then from your local computer to ResearchDrive. It also possible to use the command line:</p>
<details><summary>CHTC -&gt; ResearchDrive transfer with smbclient</summary><div class="highlight"><pre><span></span><code><span class="c1"># log into CHTC staging server and navigate to output folder</span>
ssh <span class="o">{</span>net-id<span class="o">}</span>@transfer.chtc.wisc.edu
<span class="nb">cd</span> /staging/groups/zamanian_group/output/

<span class="c1"># connect to lab ResearchDrive</span>
smbclient -k //research.drive.wisc.edu/mzamanian

<span class="c1"># turn off prompting and turn on recursive</span>
smb: <span class="se">\&gt;</span> prompt
smb: <span class="se">\&gt;</span> recurse

<span class="c1"># navigate to ResearchDrive dir for processed data (example)</span>
smb: <span class="se">\&gt;</span> <span class="nb">cd</span> /ImageXpress/proc/

<span class="c1"># transfer output data folder (example)</span>
smb: <span class="se">\&gt;</span> mput <span class="m">20201119</span>-p01-MZ_200.tar
</code></pre></div>
</details>
<p>Output data can also be transferred to your computer directly from the CHTC (as shown in the command below), or from the mounted ResearchDrive if the data have already been moved to ResearchDrive.</p>
<p><code>scp -r {net-id}@transfer.chtc.wisc.edu:/staging/groups/zamanian_group/output/[dir] .</code></p>
</li>
</ol>
<h2 id="b-docker">B. Docker</h2>
<p>We will user Docker to establish consistent environments (containers) for our established pipelines. We will maintain Docker images on <a href="https://hub.docker.com/orgs/zamanianlab">Docker Hub</a> under the organization name 'zamanianlab'. These images can be directly loaded from Docker Hub in our CHTC submit scripts. The Dockerfiles used to create these images should be maintained in our <a href="https://github.com/zamanianlab/Docker Install">GitHub Docker Repo</a>. Install <a href="https://docs.docker.com/docker-for-mac/install/">Docker Desktop for Mac</a> and create a Dockerhub account to be associated with our organization Docker Hub (zamanianlab).</p>
<h3 id="building-docker-images">Building Docker Images</h3>
<ol>
<li>
<p>Create a lab Docker Hub repo (zamanianlab/{pipeline}), which is associated with a GitHub repo called {pipeline}</p>
</li>
<li>
<p>Create Dockerfile and auxillary (e.g., yaml) files in a folder with the repo name in the <a href="https://github.com/zamanianlab/Docker Install">Docker GitHub repo</a>.</p>
<p>The Dockerfile provides instructions to build a Docker image. In this case, we are starting with the official miniconda Docker image and then installing necessary conda packages into this image. You can search for existing Docker images on <a href="https://hub.docker.com/orgs/zamanianlab">Docker Hub</a> to build on, instead of starting from scratch.</p>
<details><summary>Dockerfile</summary><div class="highlight"><pre><span></span><code>FROM continuumio/miniconda3
MAINTAINER mzamanian@wisc.edu

# install (nf tracing)
RUN apt-get update &amp;&amp; apt-get install -y procps

# install conda packages
COPY conda_env.yml .
RUN \
   conda env update -n root -f conda_env.yml \
&amp;&amp; conda clean -a
</code></pre></div>
</details>
<p>The following yml file lists <code>conda</code> packages to be installed. You can search for packages on <a href="https://anaconda.org/">Anaconda cloud</a>.</p>
<details><summary>conda_env.yml</summary><div class="highlight"><pre><span></span><code>conda_env.yaml
  name: rnaseq-nf

  channels:
    - bioconda
    - conda-forge
    - defaults

  dependencies:
    - python=3.8.5
    - nextflow=20.07.1
    - bwa=0.7.17
    - hisat2=2.2.1
    - stringtie=2.1.2
    - fastqc=0.11.9
    - multiQC=1.9
    - fastp=0.20.1
    - bedtools=2.29.2
    - bedops=2.4.39
    - sambamba=0.7.0
    - samtools=1.9
    - picard=2.20.6
    - bcftools=1.9
    - snpeff=4.3.1t
    - mrbayes=3.2.7
    - trimal=1.4.1
    - mafft=7.471
    - muscle=3.8.1551
    - seqtk=1.3
    - raxml=8.2.12
    - htseq=0.12.4
    - mirdeep2=2.0.1.2
</code></pre></div>
</details>
</li>
<li>
<p>Build Docker image</p>
<div class="highlight"><pre><span></span><code><span class="nb">cd</span> <span class="o">[</span>/path/to/Dockerfile<span class="o">]</span>
docker build -t zamanianlab/chtc-rnaseq .
</code></pre></div>
</li>
<li>
<p>Test Docker image interactively</p>
<div class="highlight"><pre><span></span><code>docker run -it --rm<span class="o">=</span>TRUE zamanianlab/chtc-rnaseq /bin/bash
ctrl+D to <span class="nb">exit</span>
</code></pre></div>
</li>
<li>
<p>Push Docker image to Docker Hub</p>
<div class="highlight"><pre><span></span><code>docker push zamanianlab/chtc-rnaseq
</code></pre></div>
<details><summary>Some useful Docker commands</summary><div class="highlight"><pre><span></span><code><span class="c1"># list docker images</span>
  docker image ls <span class="o">(=</span> docker images<span class="o">)</span>

<span class="c1"># remove images</span>
  docker rmi <span class="o">[</span>image<span class="o">]</span>

<span class="c1">## remove all docker containers</span>
<span class="c1"># run first because images are attached to containers</span>
  docker rm -f <span class="k">$(</span>docker ps -a -q<span class="k">)</span>
<span class="c1"># remove every Docker image</span>
  docker rmi -f <span class="k">$(</span>docker images -q<span class="k">)</span>
</code></pre></div>
</details>
</li>
</ol>
<h3 id="testing-docker-pipelines">Testing Docker Pipelines</h3>
<p>Before deploying a new pipeline on large datasets, test the pipeline using subsampled data. You can test locally with subsampled data, on the CHTC server with subsampled data, and finally, run the pipeline on the CHTC server with your full dataset. An example is provided below, using RNAseq data.</p>
<ol>
<li>
<p>First, subsample your data into a more manageable size and store it in the staging <code>subsampled</code> folder.</p>
</li>
<li>
<p>Run Docker container locally</p>
<div class="highlight"><pre><span></span><code>docker run -it --rm<span class="o">=</span>TRUE zamanianlab/chtc-rnaseq:v2 /bin/bash
</code></pre></div>
</li>
<li>
<p>Simulate the steps in your submit scripts</p>
<details><summary>Running commands in local Docker container</summary><div class="highlight"><pre><span></span><code><span class="c1"># set home to working directory</span>
<span class="nb">export</span> <span class="nv">HOME</span><span class="o">=</span><span class="nv">$PWD</span>

<span class="c1"># make input, work, and output directories for nextflow</span>
mkdir input work outputs

<span class="c1"># clone GitHub repo that contains pipeline in development</span>
git clone https://github.com/zamanianlab/Core_RNAseq-nf.git

<span class="c1"># transfer sub-sampled files from CHTC staging into your input folder</span>
scp -r <span class="o">{</span>net-id<span class="o">}</span>@transfer.chtc.wisc.edu:/staging/groups/zamanian_group/subsampled/191211_AHMMC5DMXX.tar input

<span class="c1"># run your pipeline commands</span>

<span class="c1"># example of a nextflow command using chtc-local.config matched to your hardware specs</span>
nextflow run Core_RNAseq-nf/WB-pe.nf -w work -c Core_RNAseq-nf/chtc-local.config --dir <span class="s2">&quot;191211_AHMMC5DMXX&quot;</span> --release <span class="s2">&quot;WBPS14&quot;</span> --species <span class="s2">&quot;brugia_malayi&quot;</span> --prjn <span class="s2">&quot;PRJNA10729&quot;</span> --rlen <span class="s2">&quot;150&quot;</span>
</code></pre></div>
</details>
</li>
<li>
<p>Make changes to your GitHub pipeline, <code>push</code> those changes to GitHub, <code>pull</code> those changes to your local container, and re-run the Nextflow command until the pipeline is behaving as expected.</p>
</li>
</ol>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../pipelines_local/" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Local Pipelines
              </div>
            </div>
          </a>
        
        
          <a href="../pipelines_wrmxpress/" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                wrmXpress Pipelines
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/vendor.0ac82a11.min.js"></script>
      <script src="../assets/javascripts/bundle.f81dfb4d.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script>
      
      <script>
        app = initialize({
          base: "..",
          features: ['instant'],
          search: Object.assign({
            worker: "../assets/javascripts/worker/search.4ac00218.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="../javascripts/extra.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>